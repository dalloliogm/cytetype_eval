{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e81f8de",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-13T14:50:32.196764Z",
     "iopub.status.busy": "2025-08-13T14:50:32.196516Z",
     "iopub.status.idle": "2025-08-13T16:47:20.969603Z",
     "shell.execute_reply": "2025-08-13T16:47:20.968753Z"
    },
    "papermill": {
     "duration": 7008.777336,
     "end_time": "2025-08-13T16:47:20.970820",
     "exception": false,
     "start_time": "2025-08-13T14:50:32.193484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/cudf/pandas/fast_slow_proxy.py:28: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pairwise feature combinations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:05<00:00, 22.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting cross-validation training...\n",
      "\n",
      "=== Fold 1/10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Encoding: 100%|██████████| 120/120 [01:28<00:00,  1.36it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 0.976710\n",
      "\n",
      "=== Fold 2/10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Encoding: 100%|██████████| 120/120 [01:25<00:00,  1.41it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: 0.976026\n",
      "\n",
      "=== Fold 3/10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Encoding: 100%|██████████| 120/120 [01:24<00:00,  1.41it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: 0.975317\n",
      "\n",
      "=== Fold 4/10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Encoding: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.976476\n",
      "\n",
      "=== Fold 5/10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Encoding: 100%|██████████| 120/120 [01:24<00:00,  1.41it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: 0.976066\n",
      "\n",
      "=== Fold 6/10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Encoding: 100%|██████████| 120/120 [01:25<00:00,  1.41it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6: 0.976563\n",
      "\n",
      "=== Fold 7/10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Encoding: 100%|██████████| 120/120 [01:25<00:00,  1.41it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7: 0.976433\n",
      "\n",
      "=== Fold 8/10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Encoding: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8: 0.975196\n",
      "\n",
      "=== Fold 9/10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Encoding: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9: 0.975812\n",
      "\n",
      "=== Fold 10/10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Encoding: 100%|██████████| 120/120 [01:24<00:00,  1.41it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10: 0.976610\n",
      "\n",
      "Final CV AUC: 0.976341\n",
      "CV AUC std: 0.000511\n",
      "\n",
      "Training complete!\n",
      "Files saved:\n",
      "- submission.csv\n",
      "- xgb_oof.csv (out-of-fold predictions)\n",
      "- xgb_pred.csv (test predictions)\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# KAGGLE COMPETITION: Playground Series S5E8 - Bank Marketing Campaign\n",
    "# Advanced XGBoost Model with Comprehensive Feature Engineering\n",
    "# IMPROVED VERSION - Removed unnecessary scaling optimization\n",
    "# ====================================================================\n",
    "\n",
    "%load_ext cudf.pandas\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from pandas.errors import PerformanceWarning\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import combinations\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=PerformanceWarning)\n",
    "\n",
    "# ====================================================================\n",
    "# DATA PREPARATION AND FEATURE DEFINITIONS\n",
    "# ====================================================================\n",
    "\n",
    "TARGET = 'y'\n",
    "NUMS = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "CATS = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "\n",
    "# Load datasets: competition train/test + original dataset for augmentation\n",
    "train = pd.read_csv('/kaggle/input/playground-series-s5e8/train.csv', index_col='id')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s5e8/test.csv', index_col='id')\n",
    "orig = pd.read_csv('/kaggle/input/bank-marketing-dataset-full/bank-full.csv', delimiter=';')\n",
    "\n",
    "# Convert target to binary (yes=1, no=0) for original dataset\n",
    "orig['y'] = orig['y'].replace({'yes': 1, 'no': 0})\n",
    "\n",
    "# Convert categorical columns to category dtype for memory efficiency and XGBoost optimization\n",
    "train[CATS] = train[CATS].astype('category')\n",
    "test[CATS] = test[CATS].astype('category')\n",
    "orig[CATS] = orig[CATS].astype('category')\n",
    "\n",
    "# ====================================================================\n",
    "# ADVANCED FEATURE ENGINEERING: PAIRWISE COMBINATIONS\n",
    "# ====================================================================\n",
    "\n",
    "TE_columns = []\n",
    "columns = NUMS + CATS\n",
    "\n",
    "print(\"Creating pairwise feature combinations...\")\n",
    "for r in [2]:\n",
    "    for cols in tqdm(list(combinations(columns, r))):\n",
    "        name = '-'.join(cols)\n",
    "\n",
    "        # Create combination features by concatenating string representations\n",
    "        train[name] = train[cols[0]].astype(str)\n",
    "        for col in cols[1:]:\n",
    "            train[name] = train[name] + '_' + train[col].astype(str)\n",
    "\n",
    "        test[name] = test[cols[0]].astype(str)\n",
    "        for col in cols[1:]:\n",
    "            test[name] = test[name] + '_' + test[col].astype(str)\n",
    "\n",
    "        orig[name] = orig[cols[0]].astype(str)\n",
    "        for col in cols[1:]:\n",
    "            orig[name] = orig[name] + '_' + orig[col].astype(str)\n",
    "        \n",
    "        # Apply consistent encoding across datasets\n",
    "        combined = pd.concat([train[name], test[name], orig[name]], ignore_index=True)\n",
    "        combined, _ = combined.factorize()\n",
    "        train[name] = combined[:len(train)]\n",
    "        test[name] = combined[len(train):len(train) + len(test)]\n",
    "        orig[name] = combined[len(train) + len(test):]\n",
    "\n",
    "        TE_columns.append(name)\n",
    "\n",
    "FEATURES = train.columns.tolist()\n",
    "FEATURES.remove(TARGET)\n",
    "\n",
    "# ====================================================================\n",
    "# ADVANCED TARGET ENCODING WITH REGULARIZATION\n",
    "# ====================================================================\n",
    "\n",
    "def target_encode_advanced(train, valid, test, col, target=TARGET, kfold=5, smooth=3):\n",
    "    \"\"\"\n",
    "    Advanced target encoding with cross-validation to prevent overfitting\n",
    "    \"\"\"\n",
    "    train['kfold'] = ((train.index) % kfold)\n",
    "    col_name = '_'.join(col)\n",
    "    train[f'TE_MEAN_' + col_name] = 0.\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    for i in range(kfold):\n",
    "        df_tmp = train[train['kfold'] != i]\n",
    "        mn = train[target].mean()\n",
    "        \n",
    "        df_tmp = df_tmp[col + [target]].groupby(col).agg(['mean', 'count']).reset_index()\n",
    "        df_tmp.columns = col + ['mean', 'count']\n",
    "        df_tmp['TE_tmp'] = ((df_tmp['mean'] * df_tmp['count']) + (mn * smooth)) / (df_tmp['count'] + smooth)\n",
    "        \n",
    "        df_tmp_m = train[col + ['kfold', f'TE_MEAN_' + col_name]].merge(df_tmp, how='left', left_on=col, right_on=col)\n",
    "        df_tmp_m.loc[df_tmp_m['kfold'] == i, f'TE_MEAN_' + col_name] = df_tmp_m.loc[df_tmp_m['kfold'] == i, 'TE_tmp']\n",
    "        train[f'TE_MEAN_' + col_name] = df_tmp_m[f'TE_MEAN_' + col_name].fillna(mn).values\n",
    "\n",
    "    # Encode validation and test sets\n",
    "    df_tmp = train[col + [target]].groupby(col).agg(['mean', 'count']).reset_index()\n",
    "    mn = train[target].mean()\n",
    "    df_tmp.columns = col + ['mean', 'count']\n",
    "    df_tmp['TE_tmp'] = ((df_tmp['mean'] * df_tmp['count']) + (mn * smooth)) / (df_tmp['count'] + smooth)\n",
    "    \n",
    "    df_tmp_m = valid[col].merge(df_tmp, how='left', left_on=col, right_on=col)\n",
    "    valid[f'TE_MEAN_' + col_name] = df_tmp_m['TE_tmp'].fillna(mn).values\n",
    "    valid[f'TE_MEAN_' + col_name] = valid[f'TE_MEAN_' + col_name].astype('float32')\n",
    "\n",
    "    df_tmp_m = test[col].merge(df_tmp, how='left', left_on=col, right_on=col)\n",
    "    test[f'TE_MEAN_' + col_name] = df_tmp_m['TE_tmp'].fillna(mn).values\n",
    "    test[f'TE_MEAN_' + col_name] = test[f'TE_MEAN_' + col_name].astype('float32')\n",
    "\n",
    "    train = train.drop('kfold', axis=1)\n",
    "    train[f'TE_MEAN_' + col_name] = train[f'TE_MEAN_' + col_name].astype('float32')\n",
    "\n",
    "    return (train, valid, test)\n",
    "\n",
    "def count_encode(train, valid, test, col):\n",
    "    \"\"\"Count encoding with log transformation\"\"\"\n",
    "    counts = train[col].value_counts()\n",
    "    \n",
    "    train[f'CE_{col}'] = np.log1p(train[col].map(counts))\n",
    "    valid[f'CE_{col}'] = np.log1p(valid[col].map(counts).fillna(0))\n",
    "    test[f'CE_{col}'] = np.log1p(test[col].map(counts).fillna(0))\n",
    "    \n",
    "    return (train, valid, test)\n",
    "\n",
    "# ====================================================================\n",
    "# CROSS-VALIDATION WITH IMPROVED EFFICIENCY\n",
    "# ====================================================================\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "pred = np.zeros(len(test))\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "fold_scores = []\n",
    "models = []\n",
    "\n",
    "print(\"\\nStarting cross-validation training...\")\n",
    "for idx, (train_idx, val_idx) in enumerate(rskf.split(train, train[TARGET])):\n",
    "    print(f\"\\n=== Fold {idx + 1}/10 ===\")\n",
    "    \n",
    "    X_train, X_val = train.loc[train_idx, FEATURES], train.loc[val_idx, FEATURES]\n",
    "    y_train, y_val = train.loc[train_idx, TARGET], train.loc[val_idx, TARGET]\n",
    "    X_test = test.copy()\n",
    "\n",
    "    # Data augmentation\n",
    "    X_train_orig = pd.concat([X_train, orig[FEATURES], orig[FEATURES]])\n",
    "    y_train_orig = pd.concat([y_train, orig[TARGET], orig[TARGET]])\n",
    "\n",
    "    # Apply feature encoding\n",
    "    for col in tqdm(TE_columns, desc=\"Feature Encoding\"):\n",
    "        X_train_orig, X_val, X_test = target_encode_advanced(\n",
    "            pd.concat([X_train_orig, y_train_orig], axis=1), X_val, X_test, [col], smooth=2\n",
    "        )\n",
    "        X_train_orig = X_train_orig.drop(TARGET, axis=1)\n",
    "        \n",
    "        X_train_orig, X_val, X_test = count_encode(X_train_orig, X_val, X_test, col)\n",
    "        \n",
    "        # Clean up original categorical features\n",
    "        X_train_orig = X_train_orig.drop(col, axis=1)\n",
    "        X_val = X_val.drop(col, axis=1)\n",
    "        X_test = X_test.drop(col, axis=1)\n",
    "    \n",
    "    # ====================================================================\n",
    "    # XGBOOST PARAMETERS\n",
    "    # ====================================================================\n",
    "    \n",
    "    parameters_xgboost = {\n",
    "        'n_estimators': 8000,         \n",
    "        'max_leaves': 127,            \n",
    "        'min_child_weight': 1.5,     \n",
    "        'max_depth': 0,               \n",
    "        'grow_policy': 'lossguide',   \n",
    "        'learning_rate': 0.008,      \n",
    "        'tree_method': 'hist',        \n",
    "        'subsample': 0.85,            \n",
    "        'colsample_bylevel': 0.7,     \n",
    "        'colsample_bytree': 0.75,       \n",
    "        'colsample_bynode': 0.85,     \n",
    "        'sampling_method': 'gradient_based',  \n",
    "        'reg_alpha': 2.5,             \n",
    "        'reg_lambda': 0.8,            \n",
    "        'enable_categorical': True,    \n",
    "        'max_cat_to_onehot': 1,       \n",
    "        'device': 'cuda',            \n",
    "        'n_jobs': -1,                 \n",
    "        'random_state': 42 + idx,     \n",
    "        'verbosity': 0,               \n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc'\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**parameters_xgboost)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_orig, y_train_orig, \n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=300\n",
    "    )\n",
    "    \n",
    "    # Generate predictions (no scaling needed for AUC!)\n",
    "    val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    test_pred = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    oof[val_idx] += val_pred\n",
    "    pred += test_pred\n",
    "    \n",
    "    fold_score = roc_auc_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_score)\n",
    "    print(f'Fold {idx + 1}: {fold_score:.6f}')\n",
    "    \n",
    "    models.append(model)\n",
    "    \n",
    "    # Memory cleanup\n",
    "    del X_train_orig, X_val, y_train_orig, y_val, X_test\n",
    "    gc.collect()\n",
    "\n",
    "# ====================================================================\n",
    "# FINAL PREDICTIONS - SIMPLIFIED WITHOUT UNNECESSARY SCALING\n",
    "# ====================================================================\n",
    "\n",
    "# Normalize OOF predictions (handle overlapping folds)\n",
    "fold_counts = np.zeros(len(train))\n",
    "for idx, (train_idx, val_idx) in enumerate(rskf.split(train, train[TARGET])):\n",
    "    fold_counts[val_idx] += 1\n",
    "oof = oof / fold_counts\n",
    "\n",
    "# Average test predictions\n",
    "pred /= 10\n",
    "\n",
    "print(f'\\nFinal CV AUC: {roc_auc_score(train[TARGET], oof):.6f}')\n",
    "print(f'CV AUC std: {np.std(fold_scores):.6f}')\n",
    "\n",
    "# ====================================================================\n",
    "# SUBMISSION - NO UNNECESSARY OPTIMIZATION\n",
    "# ====================================================================\n",
    "\n",
    "submission = pd.read_csv('/kaggle/input/playground-series-s5e8/sample_submission.csv')\n",
    "submission['y'] = pred  # Direct use without scaling\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Save predictions for ensembling\n",
    "pd.DataFrame({'xgb_oof': oof}).to_csv('xgb_oof.csv', index=False)\n",
    "pd.DataFrame({'xgb_pred': pred}).to_csv('xgb_pred.csv', index=False)\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(\"Files saved:\")\n",
    "print(\"- submission.csv\")\n",
    "print(\"- xgb_oof.csv (out-of-fold predictions)\")  \n",
    "print(\"- xgb_pred.csv (test predictions)\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12937777,
     "sourceId": 91719,
     "sourceType": "competition"
    },
    {
     "datasetId": 5626665,
     "sourceId": 9293783,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7018.703851,
   "end_time": "2025-08-13T16:47:25.080473",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-13T14:50:26.376622",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
