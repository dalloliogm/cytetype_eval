{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":12564646,"sourceType":"datasetVersion","datasetId":7934362}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Gemma and QWEN7B\n\nThis notebook uses two Models, Qwen7B and Gemma, to classify the posts.\n\nIt will then ensemble the two predictions. I don't know how to best ensemble the two models yet, for now we'll average.\n\n\nCredits: Kudos to the authors of these notebooks. Thanks for sharing:\n- https://www.kaggle.com/code/yangyefd/batch-gemma3-sample-rules-classification\n- https://www.kaggle.com/code/aerdem4/jigsaw-acrc-qwen7b-finetune-logits-processor-zoo","metadata":{}},{"cell_type":"markdown","source":"## How to install dependencies\n\nInteractive notebooks: Click on Add-Ons->Install Dependencies, then Run.\n\nSubmission: Dependencies will be installed automatically","metadata":{"execution":{"iopub.status.busy":"2025-07-25T09:31:47.893965Z","iopub.execute_input":"2025-07-25T09:31:47.894246Z","iopub.status.idle":"2025-07-25T09:38:21.881149Z","shell.execute_reply.started":"2025-07-25T09:31:47.894228Z","shell.execute_reply":"2025-07-25T09:38:21.880295Z"}}},{"cell_type":"markdown","source":"## Prepare Qwen7b and Gemma","metadata":{}},{"cell_type":"code","source":"import vllm, torch\nfrom logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T10:14:38.598330Z","iopub.execute_input":"2025-07-25T10:14:38.598542Z","iopub.status.idle":"2025-07-25T10:14:38.602123Z","shell.execute_reply.started":"2025-07-25T10:14:38.598522Z","shell.execute_reply":"2025-07-25T10:14:38.601337Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\n\nqwen7b_model_path = \"/kaggle/input/jigsaw-acrc-qwen7b-v01\"\n\nqwen7b = vllm.LLM(\n    qwen7b_model_path,\n    tensor_parallel_size=torch.cuda.device_count(),\n    gpu_memory_utilization=0.95,\n    trust_remote_code=True,\n    dtype=\"half\",\n    enforce_eager=True,\n    max_model_len=4096,\n    disable_log_stats=True,\n    enable_prefix_caching=True\n)\nqwen7b_tokenizer = qwen7b.get_tokenizer()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-25T10:20:31.685145Z","iopub.execute_input":"2025-07-25T10:20:31.685401Z","iopub.status.idle":"2025-07-25T10:23:24.530621Z","shell.execute_reply.started":"2025-07-25T10:20:31.685381Z","shell.execute_reply":"2025-07-25T10:23:24.529776Z"}},"outputs":[{"name":"stdout","text":"INFO 07-25 10:20:45 [config.py:1604] Using max model len 4096\nWARNING 07-25 10:20:45 [arg_utils.py:1690] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \nWARNING 07-25 10:20:46 [cuda.py:103] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\nINFO 07-25 10:20:46 [llm_engine.py:228] Initializing a V0 LLM engine (v0.10.0) with config: model='/kaggle/input/jigsaw-acrc-qwen7b-v01', speculative_config=None, tokenizer='/kaggle/input/jigsaw-acrc-qwen7b-v01', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/kaggle/input/jigsaw-acrc-qwen7b-v01, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":0,\"local_cache_dir\":null}, use_cached_outputs=False, \nWARNING 07-25 10:20:46 [__init__.py:2899] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\nWARNING 07-25 10:20:46 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 2 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\nINFO 07-25 10:20:47 [cuda.py:346] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\nINFO 07-25 10:20:47 [cuda.py:395] Using XFormers backend.\n","output_type":"stream"},{"name":"stderr","text":"2025-07-25 10:20:51.185111: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753438851.205554     195 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753438851.211795     195 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"INFO 07-25 10:20:56 [__init__.py:235] Automatically detected platform cuda.\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:20:56 [multiproc_worker_utils.py:226] Worker ready; awaiting tasks\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:20:57 [cuda.py:346] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:20:57 [cuda.py:395] Using XFormers backend.\n","output_type":"stream"},{"name":"stderr","text":"[W725 10:21:08.538054594 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W725 10:21:09.870660074 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W725 10:21:18.548720317 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n","output_type":"stream"},{"name":"stdout","text":"INFO 07-25 10:21:28 [__init__.py:1375] Found nccl from library libnccl.so.2\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:21:28 [__init__.py:1375] Found nccl from library libnccl.so.2\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:21:28 [pynccl.py:70] vLLM is using nccl==2.26.2\nINFO 07-25 10:21:28 [pynccl.py:70] vLLM is using nccl==2.26.2\n","output_type":"stream"},{"name":"stderr","text":"[W725 10:21:28.559105246 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n","output_type":"stream"},{"name":"stdout","text":"INFO 07-25 10:21:29 [custom_all_reduce_utils.py:208] generating GPU P2P access cache in /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\nINFO 07-25 10:21:52 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:21:52 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m WARNING 07-25 10:21:52 [custom_all_reduce.py:147] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\nWARNING 07-25 10:21:52 [custom_all_reduce.py:147] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\nINFO 07-25 10:21:52 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_c6ee07d6'), local_subscribe_addr='ipc:///tmp/b3814a5c-54dd-4546-8acc-cf4446599ec8', remote_subscribe_addr=None, remote_addr_ipv6=False)\nINFO 07-25 10:21:52 [parallel_state.py:1102] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:21:52 [parallel_state.py:1102] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\nINFO 07-25 10:21:52 [model_runner.py:1083] Starting to load model /kaggle/input/jigsaw-acrc-qwen7b-v01...\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:21:53 [model_runner.py:1083] Starting to load model /kaggle/input/jigsaw-acrc-qwen7b-v01...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c9258751fdd4f87810939edc28377a7"}},"metadata":{}},{"name":"stdout","text":"INFO 07-25 10:23:09 [default_loader.py:262] Loading weights took 75.93 seconds\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:23:09 [default_loader.py:262] Loading weights took 75.72 seconds\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:23:10 [model_runner.py:1115] Model loading took 7.1217 GiB and 75.897206 seconds\nINFO 07-25 10:23:10 [model_runner.py:1115] Model loading took 7.1217 GiB and 76.119988 seconds\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:23:16 [worker.py:295] Memory profiling takes 5.88 seconds\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:23:16 [worker.py:295] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.95) = 14.00GiB\n\u001b[1;36m(VllmWorkerProcess pid=195)\u001b[0;0m INFO 07-25 10:23:16 [worker.py:295] model weights take 7.12GiB; non_torch_memory takes 0.11GiB; PyTorch activation peak memory takes 0.36GiB; the rest of the memory reserved for KV Cache is 6.42GiB.\nINFO 07-25 10:23:16 [worker.py:295] Memory profiling takes 6.03 seconds\nINFO 07-25 10:23:16 [worker.py:295] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.95) = 14.00GiB\nINFO 07-25 10:23:16 [worker.py:295] model weights take 7.12GiB; non_torch_memory takes 0.11GiB; PyTorch activation peak memory takes 1.47GiB; the rest of the memory reserved for KV Cache is 5.30GiB.\nINFO 07-25 10:23:17 [executor_base.py:113] # cuda blocks: 12416, # CPU blocks: 9362\nINFO 07-25 10:23:17 [executor_base.py:118] Maximum concurrency for 4096 tokens per request: 48.50x\nINFO 07-25 10:23:24 [llm_engine.py:424] init engine (profile, create kv cache, warmup model) took 14.06 seconds\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"!ls /kaggle/input/gemma-7b-gguf","metadata":{"execution":{"iopub.status.busy":"2025-07-25T10:29:52.454835Z","iopub.execute_input":"2025-07-25T10:29:52.455537Z","iopub.status.idle":"2025-07-25T10:29:52.636905Z","shell.execute_reply.started":"2025-07-25T10:29:52.455502Z","shell.execute_reply":"2025-07-25T10:29:52.636020Z"},"trusted":true},"outputs":[{"name":"stdout","text":"gemma-2-9b-it.Q5_K_M.gguf  gemma-7b-it.Q5_K_M.gguf\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import vllm, torch\nfrom logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n\n\nGEMMA_PATH = \"/kaggle/input/gemma-7b-gguf/gemma-7b-it.Q5_K_M.gguf\"\n\ngemma = vllm.LLM(\n    GEMMA_PATH,\n    tensor_parallel_size=torch.cuda.device_count(),\n    gpu_memory_utilization=0.95,\n    trust_remote_code=True,\n    dtype=\"half\",\n    enforce_eager=True,\n    max_model_len=4096,\n    disable_log_stats=True,\n    enable_prefix_caching=True\n)\ngemma_tokenizer = gemma.get_tokenizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T10:31:49.194112Z","iopub.execute_input":"2025-07-25T10:31:49.194676Z","iopub.status.idle":"2025-07-25T10:32:02.810318Z","shell.execute_reply.started":"2025-07-25T10:31:49.194635Z","shell.execute_reply":"2025-07-25T10:32:02.809390Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/168067739.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mGEMMA_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/kaggle/input/gemma-7b-gguf/gemma-7b-it.Q5_K_M.gguf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m gemma = vllm.LLM(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mGEMMA_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtensor_parallel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_token, hf_overrides, mm_processor_kwargs, override_pooler_config, compilation_config, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Create the Engine (autoselects V0 vs V1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         self.llm_engine = LLMEngine.from_engine_args(\n\u001b[0m\u001b[1;32m    274\u001b[0m             engine_args=engine_args, usage_context=UsageContext.LLM_CLASS)\n\u001b[1;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm/engine/llm_engine.py\u001b[0m in \u001b[0;36mfrom_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;34m\"\"\"Creates an LLM engine from the engine arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;31m# Create the engine configs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0mvllm_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_engine_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musage_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mengine_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm/engine/arg_utils.py\u001b[0m in \u001b[0;36mcreate_engine_config\u001b[0;34m(self, usage_context, headless)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         device_config = DeviceConfig(\n\u001b[1;32m   1003\u001b[0m             device=cast(Device, current_platform.device_type))\n\u001b[0;32m-> 1004\u001b[0;31m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;31m# * If VLLM_USE_V1 is unset, we enable V1 for \"supported features\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm/engine/arg_utils.py\u001b[0m in \u001b[0;36mcreate_model_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadFormat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNAI_STREAMER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m         return ModelConfig(\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0mhf_config_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_config_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_dataclasses.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(__dataclass_self__, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__dataclass_self__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArgsKwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0m__init__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{cls.__qualname__}.__init__'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValidationError\u001b[0m: 1 validation error for ModelConfig\n  Value error, GGUF model with architecture gemma is not supported yet. [type=value_error, input_value=ArgsKwargs((), {'model': ...attention_dtype': None}), input_type=ArgsKwargs]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"],"ename":"ValidationError","evalue":"1 validation error for ModelConfig\n  Value error, GGUF model with architecture gemma is not supported yet. [type=value_error, input_value=ArgsKwargs((), {'model': ...attention_dtype': None}), input_type=ArgsKwargs]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error","output_type":"error"}],"execution_count":41},{"cell_type":"markdown","source":"## Prepare Training data and Examples ","metadata":{}},{"cell_type":"code","source":"import os, sys\nimport pandas as pd\n\ndata_path = \"/kaggle/input/jigsaw-agile-community-rules/test.csv\" \\\n                if os.getenv('KAGGLE_IS_COMPETITION_RERUN') \\\n                else \"/kaggle/input/jigsaw-agile-community-rules/train.csv\"\n\ndf = pd.read_csv(data_path)\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T10:23:47.920770Z","iopub.execute_input":"2025-07-25T10:23:47.921102Z","iopub.status.idle":"2025-07-25T10:23:47.959232Z","shell.execute_reply.started":"2025-07-25T10:23:47.921077Z","shell.execute_reply":"2025-07-25T10:23:47.958413Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"   row_id                                               body  \\\n0       0  Banks don't want you to know this! Click here ...   \n1       1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n2       2  Lol. Try appealing the ban and say you won't d...   \n3       3  she will come your home open her legs with  an...   \n4       4  code free tyrande --->>> [Imgur](http://i.imgu...   \n5       5  I live in the US it's it possible to get in tr...   \n6       6  young kitty watching for your buddy get her he...   \n7       7  [liá»‡t dÆ°Æ¡ng](http://namkhoathientam.com/nguyen...   \n8       8  Maybe true, but that's very short-sighted. The...   \n9       9  you can sue them for negligence and try and re...   \n\n                                                rule      subreddit  \\\n0  No Advertising: Spam, referral links, unsolici...     Futurology   \n1  No Advertising: Spam, referral links, unsolici...  soccerstreams   \n2  No legal advice: Do not offer or request legal...   pcmasterrace   \n3  No Advertising: Spam, referral links, unsolici...            sex   \n4  No Advertising: Spam, referral links, unsolici...    hearthstone   \n5  No legal advice: Do not offer or request legal...  soccerstreams   \n6  No Advertising: Spam, referral links, unsolici...            sex   \n7  No Advertising: Spam, referral links, unsolici...           gifs   \n8  No legal advice: Do not offer or request legal...     The_Donald   \n9  No legal advice: Do not offer or request legal...    legaladvice   \n\n                                  positive_example_1  \\\n0  If you could tell your younger self something ...   \n1  [I wanna kiss you all over! Stunning!](http://...   \n2  Don't break up with him or call the cops.  If ...   \n3  Selling Tyrande codes for 3â‚¬ to paypal. PM. \\n...   \n4   wow!! amazing reminds me of the old days.Well...   \n5  Public School? You are under no legal obligati...   \n6  Save on Medicine!!  Save over $700 a month on ...   \n7  EARN MONEY in online . Just Sign up and View f...   \n8  OP, you need to get the fuck away from your bo...   \n9  IIRC the laws require photo id, and social sec...   \n\n                                  positive_example_2  \\\n0  hunt for lady for jack off in neighbourhood ht...   \n1  LOLGA.COM is One of the First Professional Onl...   \n2  It'll be dismissed: https://en.wikipedia.org/w...   \n3  tight pussy watch for your cock get her at thi...   \n4  seek for lady for sex in around http://p77.pl/...   \n5  OP, you need to get the fuck away from your bo...   \n6  Make your life comfortable. Get up to 15% Disc...   \n7  You can use www.easy-lol.com/probuilds/\\n\\nIt ...   \n8  Steal the dogs back and put a lean on all her ...   \n9  Tell them you want to take possession of the a...   \n\n                                  negative_example_1  \\\n0  Watch Golden Globe Awards 2017 Live Online in ...   \n1  #Rapper \\nðŸš¨Straight Outta Cross Keys SC ðŸš¨YouTu...   \n2  Where is there a site that still works where y...   \n3  NSFW(obviously) http://spankbang.com/iy3u/vide...   \n4  must be watch movie https://sites.google.com/s...   \n5  It looks like it could be a sterile cotton swa...   \n6  They have nothing on the platypus though goo.g...   \n7  HD | [English Stream](http://www.ufc187livestr...   \n8  Is this 100% legal tho? Are their any copyrigh...   \n9  That is called battery.  Two wrongs don't make...   \n\n                                  negative_example_2  rule_violation  \n0  DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...               0  \n1  [15 Amazing Hidden Features Of Google Search Y...               0  \n2  Because this statement of his is true. It isn'...               1  \n3  Good News ::Download WhatsApp 2.16.230 APK for...               1  \n4  We're streaming Pokemon Veitnamese Crystal RIG...               1  \n5  That is called battery.  Two wrongs don't make...               0  \n6  Try and see if someone at www.siddhantayoga.co...               0  \n7  * **SD - http://livestreamnba.ru/2016/12/19/pr...               0  \n8  If you masturbate before the age of 18, you're...               1  \n9  Heard you might have their address, it could b...               1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>body</th>\n      <th>rule</th>\n      <th>subreddit</th>\n      <th>positive_example_1</th>\n      <th>positive_example_2</th>\n      <th>negative_example_1</th>\n      <th>negative_example_2</th>\n      <th>rule_violation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Banks don't want you to know this! Click here ...</td>\n      <td>No Advertising: Spam, referral links, unsolici...</td>\n      <td>Futurology</td>\n      <td>If you could tell your younger self something ...</td>\n      <td>hunt for lady for jack off in neighbourhood ht...</td>\n      <td>Watch Golden Globe Awards 2017 Live Online in ...</td>\n      <td>DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>SD Stream [ ENG Link 1] (http://www.sportsstre...</td>\n      <td>No Advertising: Spam, referral links, unsolici...</td>\n      <td>soccerstreams</td>\n      <td>[I wanna kiss you all over! Stunning!](http://...</td>\n      <td>LOLGA.COM is One of the First Professional Onl...</td>\n      <td>#Rapper \\nðŸš¨Straight Outta Cross Keys SC ðŸš¨YouTu...</td>\n      <td>[15 Amazing Hidden Features Of Google Search Y...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Lol. Try appealing the ban and say you won't d...</td>\n      <td>No legal advice: Do not offer or request legal...</td>\n      <td>pcmasterrace</td>\n      <td>Don't break up with him or call the cops.  If ...</td>\n      <td>It'll be dismissed: https://en.wikipedia.org/w...</td>\n      <td>Where is there a site that still works where y...</td>\n      <td>Because this statement of his is true. It isn'...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>she will come your home open her legs with  an...</td>\n      <td>No Advertising: Spam, referral links, unsolici...</td>\n      <td>sex</td>\n      <td>Selling Tyrande codes for 3â‚¬ to paypal. PM. \\n...</td>\n      <td>tight pussy watch for your cock get her at thi...</td>\n      <td>NSFW(obviously) http://spankbang.com/iy3u/vide...</td>\n      <td>Good News ::Download WhatsApp 2.16.230 APK for...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n      <td>No Advertising: Spam, referral links, unsolici...</td>\n      <td>hearthstone</td>\n      <td>wow!! amazing reminds me of the old days.Well...</td>\n      <td>seek for lady for sex in around http://p77.pl/...</td>\n      <td>must be watch movie https://sites.google.com/s...</td>\n      <td>We're streaming Pokemon Veitnamese Crystal RIG...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>I live in the US it's it possible to get in tr...</td>\n      <td>No legal advice: Do not offer or request legal...</td>\n      <td>soccerstreams</td>\n      <td>Public School? You are under no legal obligati...</td>\n      <td>OP, you need to get the fuck away from your bo...</td>\n      <td>It looks like it could be a sterile cotton swa...</td>\n      <td>That is called battery.  Two wrongs don't make...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>young kitty watching for your buddy get her he...</td>\n      <td>No Advertising: Spam, referral links, unsolici...</td>\n      <td>sex</td>\n      <td>Save on Medicine!!  Save over $700 a month on ...</td>\n      <td>Make your life comfortable. Get up to 15% Disc...</td>\n      <td>They have nothing on the platypus though goo.g...</td>\n      <td>Try and see if someone at www.siddhantayoga.co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>[liá»‡t dÆ°Æ¡ng](http://namkhoathientam.com/nguyen...</td>\n      <td>No Advertising: Spam, referral links, unsolici...</td>\n      <td>gifs</td>\n      <td>EARN MONEY in online . Just Sign up and View f...</td>\n      <td>You can use www.easy-lol.com/probuilds/\\n\\nIt ...</td>\n      <td>HD | [English Stream](http://www.ufc187livestr...</td>\n      <td>* **SD - http://livestreamnba.ru/2016/12/19/pr...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Maybe true, but that's very short-sighted. The...</td>\n      <td>No legal advice: Do not offer or request legal...</td>\n      <td>The_Donald</td>\n      <td>OP, you need to get the fuck away from your bo...</td>\n      <td>Steal the dogs back and put a lean on all her ...</td>\n      <td>Is this 100% legal tho? Are their any copyrigh...</td>\n      <td>If you masturbate before the age of 18, you're...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>you can sue them for negligence and try and re...</td>\n      <td>No legal advice: Do not offer or request legal...</td>\n      <td>legaladvice</td>\n      <td>IIRC the laws require photo id, and social sec...</td>\n      <td>Tell them you want to take possession of the a...</td>\n      <td>That is called battery.  Two wrongs don't make...</td>\n      <td>Heard you might have their address, it could b...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"## Preparing Prompts","metadata":{}},{"cell_type":"code","source":"SYS_PROMPT = \"\"\"\nYou are given a comment on reddit. Your task is to classify if it violates the given rule. Only respond Yes/No.\n\"\"\"\n\nqwen7b_prompts = []\ngemma_prompts = []\nfor i, row in df.iterrows():\n    text = f\"\"\"\nr/{row.subreddit}\nRule: {row.rule}\n\n1) {row.positive_example_1}\nViolation: Yes\n\n2) {row.negative_example_1}\nViolation: No\n\n3) {row.negative_example_2}\nViolation: No\n\n4) {row.positive_example_2}\nViolation: Yes\n\n5) {row.body}\n\"\"\"\n    print(text)\n    \n    messages = [\n        {\"role\": \"system\", \"content\": SYS_PROMPT},\n        {\"role\": \"user\", \"content\": text}\n    ]\n\n    qwen_prompt = qwen7b_tokenizer.apply_chat_template(\n        messages,\n        add_generation_prompt=True,\n        tokenize=False,\n    ) + \"Violation: \"\n    qwen7b_prompts.append(qwen_prompt)\n    gemma_prompt = gemma_tokenizer.apply_chat_template(\n        messages,\n        add_generation_prompt=True,\n        tokenize=False,\n    ) + \"Violation: \"\n    qwen7b_prompts.append(gemma_prompt)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T10:20:18.560262Z","iopub.execute_input":"2025-07-25T10:20:18.560862Z","iopub.status.idle":"2025-07-25T10:20:18.585961Z","shell.execute_reply.started":"2025-07-25T10:20:18.560837Z","shell.execute_reply":"2025-07-25T10:20:18.585074Z"}},"outputs":[{"name":"stdout","text":"\nr/Futurology\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\n\n1) If you could tell your younger self something different about sex, what would that be?\n\ni AM IN A CONTEST TO WIN FUNDING FOR MY SEX POSITIVE FILM: VOTE HERE:\n\nhttp://sheknows.offerpop.com/campaign/813112/entry/v144417\nViolation: Yes\n\n2) Watch Golden Globe Awards 2017 Live Online in HD Coverage without ADS (VIP STREAMS)\n=\n\nHD STREAM QUALITY >>> [WATCH LINK1](http://forum.submitexpress.com/viewtopic.php?f=9&t=215858)\n=\n\nHD BROADCASTING QUALITY >>> [WATCH LINK1](http://forum.submitexpress.com/viewtopic.php?f=9&t=215858)\n=\n\nMobile Compatibility: YES\n=\n\nNO ADS | NO ADS | ADS\n=\n\nViolation: No\n\n3) DOUBLE CEE x BANDS EPPS - \"BIRDS\"\n\nDOWNLOAD/STREAM:\n\nhttp://music.theblacksmithed.com/download/birds/\nViolation: No\n\n4) hunt for lady for jack off in neighbourhood http://url.inmusi.com/gakq\nViolation: Yes\n\n5) Banks don't want you to know this! Click here to know more!\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2808729329.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     ]\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     qwen_prompt = qwen7b_tokenizer.apply_chat_template(\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0madd_generation_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'qwen7b_tokenizer' is not defined"],"ename":"NameError","evalue":"name 'qwen7b_tokenizer' is not defined","output_type":"error"}],"execution_count":31},{"cell_type":"markdown","source":"## Predict / Apply MultiChoice processor","metadata":{}},{"cell_type":"code","source":"qwen_mclp = MultipleChoiceLogitsProcessor(qwen7b_tokenizer, \n                                     choices=[\"Yes\", \"No\"])\n\nqwen7b_outputs = qwen7b_llm.generate(\n    prompts,\n    vllm.SamplingParams(\n        seed=0,\n        skip_special_tokens=True,\n        max_tokens=1,\n        logits_processors=[mclp],\n        logprobs=len(mclp.choices)\n\n    ),\n    use_tqdm=True\n)\n\n\nqwen7b_logprobs = []\nfor lps in [output.outputs[0].logprobs[0].values() for output in qwen7b_outputs]:\n    qwen7b_logprobs.append({lp.decoded_token: lp.logprob for lp in list(lps)})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T10:03:19.569886Z","iopub.status.idle":"2025-07-25T10:03:19.570221Z","shell.execute_reply.started":"2025-07-25T10:03:19.570044Z","shell.execute_reply":"2025-07-25T10:03:19.570074Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gemma_mclp = MultipleChoiceLogitsProcessor(gemma_tokenizer, \n                                     choices=[\"Yes\", \"No\"])\n\ngemma_outputs = gemma_llm.generate(\n    prompts,\n    vllm.SamplingParams(\n        seed=0,\n        skip_special_tokens=True,\n        max_tokens=1,\n        logits_processors=[mclp],\n        logprobs=len(mclp.choices)\n\n    ),\n    use_tqdm=True\n)\n\n\ngemma_logprobs = []\nfor lps in [output.outputs[0].logprobs[0].values() for output in gemma_outputs]:\n    gemma_logprobs.append({lp.decoded_token: lp.logprob for lp in list(lps)})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T10:03:19.571566Z","iopub.status.idle":"2025-07-25T10:03:19.571833Z","shell.execute_reply.started":"2025-07-25T10:03:19.571715Z","shell.execute_reply":"2025-07-25T10:03:19.571730Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Averaging predictions and creating a submission file\n","metadata":{}},{"cell_type":"code","source":"# Combine logprobs from Qwen and Gemma using logprob averaging\nfinal_preds = []\nfor q_lp, g_lp in zip(qwen7b_logprobs, gemma_logprobs):\n    avg_yes = (q_lp.get(\"Yes\", -999) + g_lp.get(\"Yes\", -999)) / 2\n    avg_no = (q_lp.get(\"No\", -999) + g_lp.get(\"No\", -999)) / 2\n    final_preds.append(\"Yes\" if avg_yes > avg_no else \"No\")\n\n# Format for Kaggle submission\nsubmission_df = pd.DataFrame({\n    \"example_id\": df[\"example_id\"],\n    \"label\": final_preds\n})\n\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"Saved submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T10:03:19.573076Z","iopub.status.idle":"2025-07-25T10:03:19.573380Z","shell.execute_reply.started":"2025-07-25T10:03:19.573231Z","shell.execute_reply":"2025-07-25T10:03:19.573246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Extract individual logprobs for plotting\nqwen_yes = [lp.get(\"Yes\", -999) for lp in qwen7b_logprobs]\nqwen_no  = [lp.get(\"No\", -999) for lp in qwen7b_logprobs]\n\ngemma_yes = [lp.get(\"Yes\", -999) for lp in gemma_logprobs]\ngemma_no  = [lp.get(\"No\", -999) for lp in gemma_logprobs]\n\navg_yes = [(qy + gy) / 2 for qy, gy in zip(qwen_yes, gemma_yes)]\navg_no  = [(qn + gn) / 2 for qn, gn in zip(qwen_no, gemma_no)]\n\n# Plot histograms\nplt.figure(figsize=(12, 6))\nplt.hist(qwen_yes, bins=30, alpha=0.5, label='Qwen7B - Yes', density=True)\nplt.hist(qwen_no, bins=30, alpha=0.5, label='Qwen7B - No', density=True)\nplt.hist(gemma_yes, bins=30, alpha=0.5, label='Gemma - Yes', density=True)\nplt.hist(gemma_no, bins=30, alpha=0.5, label='Gemma - No', density=True)\nplt.hist(avg_yes, bins=30, alpha=0.6, label='Avg - Yes', histtype='step', linewidth=2)\nplt.hist(avg_no, bins=30, alpha=0.6, label='Avg - No', histtype='step', linewidth=2)\n\nplt.title(\"Histogram of Logprobs for 'Yes' and 'No' Predictions\")\nplt.xlabel(\"Log Probability\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T10:03:19.574256Z","iopub.status.idle":"2025-07-25T10:03:19.574495Z","shell.execute_reply.started":"2025-07-25T10:03:19.574394Z","shell.execute_reply":"2025-07-25T10:03:19.574404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}